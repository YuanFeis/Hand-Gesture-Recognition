[general]
# no of frames for each video
nb_frames   = 16
# no of frames to skip
skip        = 1
# target_size of the input frames
target_size = (64,96)
# batch size to train the model on
batch_size  = 64
# no of epochs to train the model on
epochs      = 10
# number of classes to train the model on
nb_classes  = 27

[path]
# name of the directory where the models and weights will be saved
model_name = CNN3D_Lite
# root folder containing the data
data_root  = /home/ubuntu/gesture-recognition/
# name of the directory that will contain the models
data_model = model
# name of the directory that contains the Jester dataset
data_vid   = 20bn-jester-v1
# name of the weights file for the model
path_weights = None

# path to each csv file (from data_root)
csv_labels = 20BN-jester/annotations/jester-v1-labels.csv
csv_train  = 20BN-jester/annotations/jester-v1-train.csv
csv_val    = 20BN-jester/annotations/jester-v1-validation.csv
csv_test   = 20BN-jester/annotations/jester-v1-test.csv

[option]
# keras parameters
workers = 0
use_multiprocessing = True
max_queue_size = 20


